{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc69279-7fc6-4825-b843-9481af833a36",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SEJAL_CHOUREY(Resume_).pdf.pdf.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdfplumber\u001b[39;00m\n\u001b[0;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEJAL_CHOUREY(Resume_).pdf.pdf.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pdf:   \n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf\u001b[38;5;241m.\u001b[39mpages:\n\u001b[0;32m      6\u001b[0m         text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_text() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pdfplumber\\pdf.py:98\u001b[0m, in \u001b[0;36mPDF.open\u001b[1;34m(cls, path_or_fp, pages, laparams, password, strict_metadata, unicode_norm, repair, gs_path, repair_setting, raise_unicode_errors)\u001b[0m\n\u001b[0;32m     96\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_fp, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[1;32m---> 98\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(path_or_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m     stream_is_external \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(path_or_fp)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SEJAL_CHOUREY(Resume_).pdf.pdf.pdf'"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "text = \"\"\n",
    "with pdfplumber.open(\"SEJAL_CHOUREY(Resume_).pdf.pdf.pdf\") as pdf:   \n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8efb7a5-9540-487f-be9b-212b214bec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.11)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.11.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: pdfminer.six==20251107 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfplumber) (20251107)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfplumber) (10.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfplumber) (5.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pdfminer.six==20251107->pdfplumber) (46.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.21)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.2 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     ---- --------------------------------- 1.6/12.8 MB 912.1 kB/s eta 0:00:13\n",
      "     ---- --------------------------------- 1.6/12.8 MB 912.1 kB/s eta 0:00:13\n",
      "     ---- --------------------------------- 1.6/12.8 MB 912.1 kB/s eta 0:00:13\n",
      "     ---- --------------------------------- 1.6/12.8 MB 912.1 kB/s eta 0:00:13\n",
      "     ----- -------------------------------- 1.8/12.8 MB 704.1 kB/s eta 0:00:16\n",
      "     ------ ------------------------------- 2.1/12.8 MB 748.1 kB/s eta 0:00:15\n",
      "     ------ ------------------------------- 2.1/12.8 MB 748.1 kB/s eta 0:00:15\n",
      "     ------- ------------------------------ 2.4/12.8 MB 749.8 kB/s eta 0:00:14\n",
      "     ------- ------------------------------ 2.6/12.8 MB 758.9 kB/s eta 0:00:14\n",
      "     -------- ----------------------------- 2.9/12.8 MB 780.4 kB/s eta 0:00:13\n",
      "     --------- ---------------------------- 3.1/12.8 MB 805.9 kB/s eta 0:00:12\n",
      "     --------- ---------------------------- 3.1/12.8 MB 805.9 kB/s eta 0:00:12\n",
      "     ---------- --------------------------- 3.4/12.8 MB 815.2 kB/s eta 0:00:12\n",
      "     ---------- --------------------------- 3.4/12.8 MB 815.2 kB/s eta 0:00:12\n",
      "     ---------- --------------------------- 3.4/12.8 MB 815.2 kB/s eta 0:00:12\n",
      "     ---------- --------------------------- 3.7/12.8 MB 754.8 kB/s eta 0:00:13\n",
      "     ----------- -------------------------- 3.9/12.8 MB 775.2 kB/s eta 0:00:12\n",
      "     ------------ ------------------------- 4.2/12.8 MB 781.6 kB/s eta 0:00:12\n",
      "     ------------- ------------------------ 4.5/12.8 MB 801.4 kB/s eta 0:00:11\n",
      "     ------------- ------------------------ 4.5/12.8 MB 801.4 kB/s eta 0:00:11\n",
      "     -------------- ----------------------- 4.7/12.8 MB 803.4 kB/s eta 0:00:11\n",
      "     -------------- ----------------------- 5.0/12.8 MB 805.4 kB/s eta 0:00:10\n",
      "     -------------- ----------------------- 5.0/12.8 MB 805.4 kB/s eta 0:00:10\n",
      "     --------------- ---------------------- 5.2/12.8 MB 795.0 kB/s eta 0:00:10\n",
      "     --------------- ---------------------- 5.2/12.8 MB 795.0 kB/s eta 0:00:10\n",
      "     ---------------- --------------------- 5.5/12.8 MB 793.3 kB/s eta 0:00:10\n",
      "     ----------------- -------------------- 5.8/12.8 MB 799.0 kB/s eta 0:00:09\n",
      "     ----------------- -------------------- 5.8/12.8 MB 799.0 kB/s eta 0:00:09\n",
      "     ----------------- -------------------- 6.0/12.8 MB 800.7 kB/s eta 0:00:09\n",
      "     ------------------ ------------------- 6.3/12.8 MB 809.0 kB/s eta 0:00:09\n",
      "     ------------------- ------------------ 6.6/12.8 MB 813.5 kB/s eta 0:00:08\n",
      "     ------------------- ------------------ 6.6/12.8 MB 813.5 kB/s eta 0:00:08\n",
      "     -------------------- ----------------- 6.8/12.8 MB 812.9 kB/s eta 0:00:08\n",
      "     -------------------- ----------------- 6.8/12.8 MB 812.9 kB/s eta 0:00:08\n",
      "     --------------------- ---------------- 7.1/12.8 MB 806.3 kB/s eta 0:00:08\n",
      "     --------------------- ---------------- 7.1/12.8 MB 806.3 kB/s eta 0:00:08\n",
      "     --------------------- ---------------- 7.3/12.8 MB 794.7 kB/s eta 0:00:07\n",
      "     --------------------- ---------------- 7.3/12.8 MB 794.7 kB/s eta 0:00:07\n",
      "     ---------------------- --------------- 7.6/12.8 MB 786.9 kB/s eta 0:00:07\n",
      "     ---------------------- --------------- 7.6/12.8 MB 786.9 kB/s eta 0:00:07\n",
      "     ----------------------- -------------- 7.9/12.8 MB 774.8 kB/s eta 0:00:07\n",
      "     ----------------------- -------------- 7.9/12.8 MB 774.8 kB/s eta 0:00:07\n",
      "     ------------------------ ------------- 8.1/12.8 MB 766.1 kB/s eta 0:00:07\n",
      "     ------------------------ ------------- 8.1/12.8 MB 766.1 kB/s eta 0:00:07\n",
      "     ------------------------ ------------- 8.4/12.8 MB 766.0 kB/s eta 0:00:06\n",
      "     ------------------------- ------------ 8.7/12.8 MB 771.4 kB/s eta 0:00:06\n",
      "     -------------------------- ----------- 8.9/12.8 MB 778.7 kB/s eta 0:00:05\n",
      "     --------------------------- ---------- 9.2/12.8 MB 781.4 kB/s eta 0:00:05\n",
      "     ---------------------------- --------- 9.4/12.8 MB 789.2 kB/s eta 0:00:05\n",
      "     ---------------------------- --------- 9.4/12.8 MB 789.2 kB/s eta 0:00:05\n",
      "     ---------------------------- --------- 9.7/12.8 MB 786.4 kB/s eta 0:00:04\n",
      "     ---------------------------- --------- 9.7/12.8 MB 786.4 kB/s eta 0:00:04\n",
      "     ---------------------------- -------- 10.0/12.8 MB 786.8 kB/s eta 0:00:04\n",
      "     ---------------------------- -------- 10.0/12.8 MB 786.8 kB/s eta 0:00:04\n",
      "     ----------------------------- ------- 10.2/12.8 MB 785.2 kB/s eta 0:00:04\n",
      "     ------------------------------ ------ 10.5/12.8 MB 788.4 kB/s eta 0:00:03\n",
      "     ------------------------------- ----- 10.7/12.8 MB 795.2 kB/s eta 0:00:03\n",
      "     ------------------------------- ----- 10.7/12.8 MB 795.2 kB/s eta 0:00:03\n",
      "     ------------------------------- ----- 11.0/12.8 MB 794.3 kB/s eta 0:00:03\n",
      "     ------------------------------- ----- 11.0/12.8 MB 794.3 kB/s eta 0:00:03\n",
      "     -------------------------------- ---- 11.3/12.8 MB 783.0 kB/s eta 0:00:02\n",
      "     --------------------------------- --- 11.5/12.8 MB 789.3 kB/s eta 0:00:02\n",
      "     --------------------------------- --- 11.5/12.8 MB 789.3 kB/s eta 0:00:02\n",
      "     ---------------------------------- -- 11.8/12.8 MB 787.0 kB/s eta 0:00:02\n",
      "     ---------------------------------- -- 11.8/12.8 MB 787.0 kB/s eta 0:00:02\n",
      "     ---------------------------------- -- 12.1/12.8 MB 784.8 kB/s eta 0:00:01\n",
      "     ---------------------------------- -- 12.1/12.8 MB 784.8 kB/s eta 0:00:01\n",
      "     ----------------------------------- - 12.3/12.8 MB 780.3 kB/s eta 0:00:01\n",
      "     ----------------------------------- - 12.3/12.8 MB 780.3 kB/s eta 0:00:01\n",
      "     ------------------------------------  12.6/12.8 MB 775.4 kB/s eta 0:00:01\n",
      "     ------------------------------------  12.6/12.8 MB 775.4 kB/s eta 0:00:01\n",
      "     ------------------------------------- 12.8/12.8 MB 766.8 kB/s eta 0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy pdfplumber\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import os, re, json, random\n",
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfdc0ed-c5ab-4e9d-bd27-c7a62d31a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 118 resumes -> resumes_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "# only reads filename and text means all the data inside text \n",
    "pdf_folder = \"pdf_files\"  \n",
    "rows = []\n",
    "for fname in os.listdir(pdf_folder):\n",
    "    if not fname.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "    path = os.path.join(pdf_folder, fname)\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(\"Error reading\", fname, e)\n",
    "        continue\n",
    "    rows.append({\"filename\": fname, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"resumes_extracted.csv\", index=False)\n",
    "print(\"Extracted\", len(df), \"resumes -> resumes_extracted.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d8ebd3-008f-448e-a541-8c8366e2eb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATS_DS_Resume_1.pdf</td>\n",
       "      <td>NAME: David Kim 91\\nEmail: david_kim_91@mail.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATS_DS_Resume_10.pdf</td>\n",
       "      <td>NAME: Manisha Yadav 45\\nEmail: manisha_yadav_4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATS_DS_Resume_100.pdf</td>\n",
       "      <td>NAME: Ahmed Malik 47\\nEmail: ahmed_malik_47@ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATS_DS_Resume_11.pdf</td>\n",
       "      <td>NAME: Mia Johnson 46\\nEmail: mia_johnson_46@ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATS_DS_Resume_12.pdf</td>\n",
       "      <td>NAME: Mia Johnson 49\\nEmail: mia_johnson_49@ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>structured_resume_1.pdf</td>\n",
       "      <td>Aman Verma— SoftwareEngineer\\n+91-9876543210|a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>structured_resume_2.pdf</td>\n",
       "      <td>NishthaGupta—DataAnalyst\\n+91-9123456789|nisht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>structured_resume_3.pdf</td>\n",
       "      <td>RohitSingh—FrontendDeveloper\\n+91-9987654321|r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>structured_resume_4 (1).pdf</td>\n",
       "      <td>PriyaMenon—MachineLearningEngineer\\n+91-900001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>structured_resume_4.pdf</td>\n",
       "      <td>Priya Menon — Machine Learning Engineer\\npriya...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  \\\n",
       "0            ATS_DS_Resume_1.pdf   \n",
       "1           ATS_DS_Resume_10.pdf   \n",
       "2          ATS_DS_Resume_100.pdf   \n",
       "3           ATS_DS_Resume_11.pdf   \n",
       "4           ATS_DS_Resume_12.pdf   \n",
       "..                           ...   \n",
       "113      structured_resume_1.pdf   \n",
       "114      structured_resume_2.pdf   \n",
       "115      structured_resume_3.pdf   \n",
       "116  structured_resume_4 (1).pdf   \n",
       "117      structured_resume_4.pdf   \n",
       "\n",
       "                                                  text  \n",
       "0    NAME: David Kim 91\\nEmail: david_kim_91@mail.c...  \n",
       "1    NAME: Manisha Yadav 45\\nEmail: manisha_yadav_4...  \n",
       "2    NAME: Ahmed Malik 47\\nEmail: ahmed_malik_47@ma...  \n",
       "3    NAME: Mia Johnson 46\\nEmail: mia_johnson_46@ma...  \n",
       "4    NAME: Mia Johnson 49\\nEmail: mia_johnson_49@ma...  \n",
       "..                                                 ...  \n",
       "113  Aman Verma— SoftwareEngineer\\n+91-9876543210|a...  \n",
       "114  NishthaGupta—DataAnalyst\\n+91-9123456789|nisht...  \n",
       "115  RohitSingh—FrontendDeveloper\\n+91-9987654321|r...  \n",
       "116  PriyaMenon—MachineLearningEngineer\\n+91-900001...  \n",
       "117  Priya Menon — Machine Learning Engineer\\npriya...  \n",
       "\n",
       "[118 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c05d1bfe-6a7b-4445-ae0a-6d2c1e0e4e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ CSV saved: All_needed_entity.csv\n",
      "Total resumes processed: 118\n",
      "            name                      email             phone  \\\n",
      "0      David Kim      david_kim_91@mail.com  +91-6393136116\\n   \n",
      "1  Manisha Yadav  manisha_yadav_45@mail.com  +91-9610893319\\n   \n",
      "2    Ahmed Malik    ahmed_malik_47@mail.com  +91-7718575010\\n   \n",
      "3    Mia Johnson    mia_johnson_46@mail.com  +91-8120603783\\n   \n",
      "4    Mia Johnson    mia_johnson_49@mail.com  +91-7736163235\\n   \n",
      "\n",
      "                skills cgpa  \\\n",
      "0  python, sql, ml, ai        \n",
      "1  python, sql, ml, ai        \n",
      "2  python, sql, ml, ai        \n",
      "3  python, sql, ml, ai        \n",
      "4  python, sql, ml, ai        \n",
      "\n",
      "                                                text               filename  \n",
      "0  NAME: David Kim 91\\nEmail: david_kim_91@mail.c...    ATS_DS_Resume_1.pdf  \n",
      "1  NAME: Manisha Yadav 45\\nEmail: manisha_yadav_4...   ATS_DS_Resume_10.pdf  \n",
      "2  NAME: Ahmed Malik 47\\nEmail: ahmed_malik_47@ma...  ATS_DS_Resume_100.pdf  \n",
      "3  NAME: Mia Johnson 46\\nEmail: mia_johnson_46@ma...   ATS_DS_Resume_11.pdf  \n",
      "4  NAME: Mia Johnson 49\\nEmail: mia_johnson_49@ma...   ATS_DS_Resume_12.pdf  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------ REGEX FUNCTIONS ------------------\n",
    "def extract_email(text):\n",
    "    match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-z]{2,}\", text)\n",
    "    return match.group(0) if match else \"\"\n",
    "\n",
    "def extract_phone(text):\n",
    "    match = re.search(r\"\\+?\\d[\\d\\s\\-]{8,15}\", text)\n",
    "    return match.group(0) if match else \"\"\n",
    "\n",
    "def extract_name(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    first_line = lines[0].strip() if lines else \"\"\n",
    "\n",
    "    # Remove common prefixes \n",
    "    first_line = re.sub(r'^(name[:\\-]?\\s*)', '', first_line, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove numbers\n",
    "    first_line = re.sub(r'\\d+', '', first_line).strip()\n",
    "\n",
    "    # Keep only alphabetic words\n",
    "    words = re.findall(r'[A-Za-z]+', first_line)\n",
    "    if 1 <= len(words) <= 4:\n",
    "        return \" \".join(words)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "SKILLS = [\"python\", \"java\", \"sql\", \"excel\", \"flask\", \"django\", \"ml\", \"ai\", \"data analysis\"]\n",
    "\n",
    "def extract_skills(text):\n",
    "    text_lower = text.lower()\n",
    "    found = [skill for skill in SKILLS if skill in text_lower]\n",
    "    return \", \".join(found)\n",
    "\n",
    "def extract_cgpa(text):\n",
    "    match = re.search(r\"CGPA[:\\s-]*([\\d\\.]+)\", text, re.IGNORECASE)\n",
    "    return match.group(1) if match else \"\"\n",
    "\n",
    "# ------------------ PROCESS RESUME ------------------\n",
    "def process_resume(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + '\\n'\n",
    "    return {\n",
    "        \"name\": extract_name(text),\n",
    "        \"email\": extract_email(text),\n",
    "        \"phone\": extract_phone(text),\n",
    "        \"skills\": extract_skills(text),\n",
    "        \"cgpa\": extract_cgpa(text),\n",
    "        \"text\": text\n",
    "    }\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "pdf_folder = \"pdf_files\"\n",
    "all_rows = []\n",
    "\n",
    "for fname in os.listdir(pdf_folder):\n",
    "    if not fname.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "    path = os.path.join(pdf_folder, fname)\n",
    "    try:\n",
    "        row = process_resume(path)\n",
    "        row[\"filename\"] = fname  # add filename column\n",
    "        all_rows.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Save CSV with separate columns\n",
    "df.to_csv(\"All_needed_entity.csv\", index=False)\n",
    "print(\"✔️ CSV saved: All_needed_entity.csv\")\n",
    "print(\"Total resumes processed:\", df.shape[0])\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46010d10-322d-4948-8901-ce5add24c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Folder Path: C:\\Users\\hp\\Desktop\\enhancement_NER_on100 pdf_files\n",
      "PDF Files: ['ATS_DS_Resume_1.pdf', 'ATS_DS_Resume_10.pdf', 'ATS_DS_Resume_100.pdf', 'ATS_DS_Resume_11.pdf', 'ATS_DS_Resume_12.pdf', 'ATS_DS_Resume_13.pdf', 'ATS_DS_Resume_14.pdf', 'ATS_DS_Resume_15.pdf', 'ATS_DS_Resume_16.pdf', 'ATS_DS_Resume_17.pdf', 'ATS_DS_Resume_18.pdf', 'ATS_DS_Resume_19.pdf', 'ATS_DS_Resume_2.pdf', 'ATS_DS_Resume_20.pdf', 'ATS_DS_Resume_21.pdf', 'ATS_DS_Resume_22.pdf', 'ATS_DS_Resume_23.pdf', 'ATS_DS_Resume_24.pdf', 'ATS_DS_Resume_25.pdf', 'ATS_DS_Resume_26.pdf', 'ATS_DS_Resume_27.pdf', 'ATS_DS_Resume_28.pdf', 'ATS_DS_Resume_29.pdf', 'ATS_DS_Resume_3.pdf', 'ATS_DS_Resume_30.pdf', 'ATS_DS_Resume_31.pdf', 'ATS_DS_Resume_32.pdf', 'ATS_DS_Resume_33.pdf', 'ATS_DS_Resume_34.pdf', 'ATS_DS_Resume_35.pdf', 'ATS_DS_Resume_36.pdf', 'ATS_DS_Resume_37.pdf', 'ATS_DS_Resume_38.pdf', 'ATS_DS_Resume_39.pdf', 'ATS_DS_Resume_4.pdf', 'ATS_DS_Resume_40.pdf', 'ATS_DS_Resume_41.pdf', 'ATS_DS_Resume_42.pdf', 'ATS_DS_Resume_43.pdf', 'ATS_DS_Resume_44.pdf', 'ATS_DS_Resume_45.pdf', 'ATS_DS_Resume_46.pdf', 'ATS_DS_Resume_47.pdf', 'ATS_DS_Resume_48.pdf', 'ATS_DS_Resume_49.pdf', 'ATS_DS_Resume_5.pdf', 'ATS_DS_Resume_50.pdf', 'ATS_DS_Resume_51.pdf', 'ATS_DS_Resume_52.pdf', 'ATS_DS_Resume_53.pdf', 'ATS_DS_Resume_54.pdf', 'ATS_DS_Resume_55.pdf', 'ATS_DS_Resume_56.pdf', 'ATS_DS_Resume_57.pdf', 'ATS_DS_Resume_58.pdf', 'ATS_DS_Resume_59.pdf', 'ATS_DS_Resume_6.pdf', 'ATS_DS_Resume_60.pdf', 'ATS_DS_Resume_61.pdf', 'ATS_DS_Resume_62.pdf', 'ATS_DS_Resume_63.pdf', 'ATS_DS_Resume_64.pdf', 'ATS_DS_Resume_65.pdf', 'ATS_DS_Resume_66.pdf', 'ATS_DS_Resume_67.pdf', 'ATS_DS_Resume_68.pdf', 'ATS_DS_Resume_69.pdf', 'ATS_DS_Resume_7.pdf', 'ATS_DS_Resume_70.pdf', 'ATS_DS_Resume_71.pdf', 'ATS_DS_Resume_72.pdf', 'ATS_DS_Resume_73.pdf', 'ATS_DS_Resume_74.pdf', 'ATS_DS_Resume_75.pdf', 'ATS_DS_Resume_76.pdf', 'ATS_DS_Resume_77.pdf', 'ATS_DS_Resume_78.pdf', 'ATS_DS_Resume_79.pdf', 'ATS_DS_Resume_8.pdf', 'ATS_DS_Resume_80.pdf', 'ATS_DS_Resume_81.pdf', 'ATS_DS_Resume_82.pdf', 'ATS_DS_Resume_83.pdf', 'ATS_DS_Resume_84.pdf', 'ATS_DS_Resume_85.pdf', 'ATS_DS_Resume_86.pdf', 'ATS_DS_Resume_87.pdf', 'ATS_DS_Resume_88.pdf', 'ATS_DS_Resume_89.pdf', 'ATS_DS_Resume_9.pdf', 'ATS_DS_Resume_90.pdf', 'ATS_DS_Resume_91.pdf', 'ATS_DS_Resume_92.pdf', 'ATS_DS_Resume_93.pdf', 'ATS_DS_Resume_94.pdf', 'ATS_DS_Resume_95.pdf', 'ATS_DS_Resume_96.pdf', 'ATS_DS_Resume_97.pdf', 'ATS_DS_Resume_98.pdf', 'ATS_DS_Resume_99.pdf', 'Bharti.pdf', 'customers-1000.pdf', 'MUSKAN_RESUME ML.pdf', 'Sejal_Chourey (4).pdf', 'SEJAL_CHOUREY(Resume).pdf', 'Sejal_Chourey(resume_).pdf', 'SEJAL_CHOUREY(Resume_).pdf (1).pdf', 'SEJAL_CHOUREY(Resume_).pdf.pdf', 'SEJAL_CHOUREY_.pdf', 'SEJAL_CHOUREY_CONSAT_ORAHI.pdf.pdf', 'SEJAL_CHOUREY_DeltaX.pdf', 'Sejal_Resume.pdf.pdf', 'Shakshi resume (3).pdf', 'structured_resume_1.pdf', 'structured_resume_2.pdf', 'structured_resume_3.pdf', 'structured_resume_4 (1).pdf', 'structured_resume_4.pdf', 'Tanushree_Resume.doc.docx']\n"
     ]
    }
   ],
   "source": [
    "print(\"PDF Folder Path:\", os.getcwd(), pdf_folder)\n",
    "print(\"PDF Files:\", os.listdir(pdf_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3cfae9-3386-407d-ac41-c5549fd087b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name                      email             phone  \\\n",
      "0      David Kim      david_kim_91@mail.com  +91-6393136116\\n   \n",
      "1  Manisha Yadav  manisha_yadav_45@mail.com  +91-9610893319\\n   \n",
      "2    Ahmed Malik    ahmed_malik_47@mail.com  +91-7718575010\\n   \n",
      "3    Mia Johnson    mia_johnson_46@mail.com  +91-8120603783\\n   \n",
      "4    Mia Johnson    mia_johnson_49@mail.com  +91-7736163235\\n   \n",
      "\n",
      "                skills cgpa  \\\n",
      "0  python, sql, ml, ai        \n",
      "1  python, sql, ml, ai        \n",
      "2  python, sql, ml, ai        \n",
      "3  python, sql, ml, ai        \n",
      "4  python, sql, ml, ai        \n",
      "\n",
      "                                                text               filename  \n",
      "0  NAME: David Kim 91\\nEmail: david_kim_91@mail.c...    ATS_DS_Resume_1.pdf  \n",
      "1  NAME: Manisha Yadav 45\\nEmail: manisha_yadav_4...   ATS_DS_Resume_10.pdf  \n",
      "2  NAME: Ahmed Malik 47\\nEmail: ahmed_malik_47@ma...  ATS_DS_Resume_100.pdf  \n",
      "3  NAME: Mia Johnson 46\\nEmail: mia_johnson_46@ma...   ATS_DS_Resume_11.pdf  \n",
      "4  NAME: Mia Johnson 49\\nEmail: mia_johnson_49@ma...   ATS_DS_Resume_12.pdf  \n",
      "(118, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9120029-30ea-438c-bb38-e77c1310ffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Dir: C:\\Users\\hp\\Desktop\\enhancement_NER_on100\n",
      "['.ipynb_checkpoints', 'All_needed_entity.csv', 'app.py', 'ATS_DS_100_Unique_Names_Phones', 'cgpa.txt', 'emails.txt', 'names.txt', 'NER_100resumes.ipynb', 'NER_custom_model.ipynb', 'NER_custom_model.py', 'pdf_files', 'phones.txt', 'resumes_cleaned.csv', 'resumes_extracted.csv', 'resumes_extracted_new.csv', 'resume_ner_model_v1', 'skills.txt', 'sql_snowflake.ipynb', 'templates', 'train_candidates.json', 'ui.ipynb', 'untitled.py', 'upload_csv_to_s3.ipynb', 'upload_csv_to_s3.py', 'watcher.ipynb', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Dir:\", os.getcwd())\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaa5f208-e352-476f-8c02-11416f53649b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>skills</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATS_DS_Resume_1.pdf</td>\n",
       "      <td>David Kim</td>\n",
       "      <td>david_kim_91@mail.com</td>\n",
       "      <td>+91-6393136116\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: David Kim 91\\nEmail: david_kim_91@mail.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATS_DS_Resume_10.pdf</td>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>manisha_yadav_45@mail.com</td>\n",
       "      <td>+91-9610893319\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: Manisha Yadav 45\\nEmail: manisha_yadav_4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATS_DS_Resume_100.pdf</td>\n",
       "      <td>Ahmed Malik</td>\n",
       "      <td>ahmed_malik_47@mail.com</td>\n",
       "      <td>+91-7718575010\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: Ahmed Malik 47\\nEmail: ahmed_malik_47@ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATS_DS_Resume_11.pdf</td>\n",
       "      <td>Mia Johnson</td>\n",
       "      <td>mia_johnson_46@mail.com</td>\n",
       "      <td>+91-8120603783\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: Mia Johnson 46\\nEmail: mia_johnson_46@ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATS_DS_Resume_12.pdf</td>\n",
       "      <td>Mia Johnson</td>\n",
       "      <td>mia_johnson_49@mail.com</td>\n",
       "      <td>+91-7736163235\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: Mia Johnson 49\\nEmail: mia_johnson_49@ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename           name                      email  \\\n",
       "0    ATS_DS_Resume_1.pdf      David Kim      david_kim_91@mail.com   \n",
       "1   ATS_DS_Resume_10.pdf  Manisha Yadav  manisha_yadav_45@mail.com   \n",
       "2  ATS_DS_Resume_100.pdf    Ahmed Malik    ahmed_malik_47@mail.com   \n",
       "3   ATS_DS_Resume_11.pdf    Mia Johnson    mia_johnson_46@mail.com   \n",
       "4   ATS_DS_Resume_12.pdf    Mia Johnson    mia_johnson_49@mail.com   \n",
       "\n",
       "              phone               skills  cgpa  \\\n",
       "0  +91-6393136116\\n  python, sql, ml, ai   NaN   \n",
       "1  +91-9610893319\\n  python, sql, ml, ai   NaN   \n",
       "2  +91-7718575010\\n  python, sql, ml, ai   NaN   \n",
       "3  +91-8120603783\\n  python, sql, ml, ai   NaN   \n",
       "4  +91-7736163235\\n  python, sql, ml, ai   NaN   \n",
       "\n",
       "                                                text  \n",
       "0  NAME: David Kim 91\\nEmail: david_kim_91@mail.c...  \n",
       "1  NAME: Manisha Yadav 45\\nEmail: manisha_yadav_4...  \n",
       "2  NAME: Ahmed Malik 47\\nEmail: ahmed_malik_47@ma...  \n",
       "3  NAME: Mia Johnson 46\\nEmail: mia_johnson_46@ma...  \n",
       "4  NAME: Mia Johnson 49\\nEmail: mia_johnson_49@ma...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"resumes_extracted_new.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cd0423c-ea92-45f7-a3ec-472d614d17fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>skills</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Kim</td>\n",
       "      <td>david_kim_91@mail.com</td>\n",
       "      <td>+91-6393136116\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: David Kim 91\\nEmail: david_kim_91@mail.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>manisha_yadav_45@mail.com</td>\n",
       "      <td>+91-9610893319\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: Manisha Yadav 45\\nEmail: manisha_yadav_4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmed Malik</td>\n",
       "      <td>ahmed_malik_47@mail.com</td>\n",
       "      <td>+91-7718575010\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: Ahmed Malik 47\\nEmail: ahmed_malik_47@ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mia Johnson</td>\n",
       "      <td>mia_johnson_46@mail.com</td>\n",
       "      <td>+91-8120603783\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: Mia Johnson 46\\nEmail: mia_johnson_46@ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mia Johnson</td>\n",
       "      <td>mia_johnson_49@mail.com</td>\n",
       "      <td>+91-7736163235\\n</td>\n",
       "      <td>python, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAME: Mia Johnson 49\\nEmail: mia_johnson_49@ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Aman Verma SoftwareEngineer</td>\n",
       "      <td>aman.verma@example.com</td>\n",
       "      <td>+91-9876543210</td>\n",
       "      <td>python, java, sql, flask</td>\n",
       "      <td>6.50</td>\n",
       "      <td>Aman Verma— SoftwareEngineer\\n+91-9876543210|a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NishthaGupta DataAnalyst</td>\n",
       "      <td>nishtha.gupta@example.com</td>\n",
       "      <td>+91-9123456789</td>\n",
       "      <td>python, sql, excel, ai</td>\n",
       "      <td>7.42</td>\n",
       "      <td>NishthaGupta—DataAnalyst\\n+91-9123456789|nisht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>RohitSingh FrontendDeveloper</td>\n",
       "      <td>rohit.singh@example.com</td>\n",
       "      <td>+91-9987654321</td>\n",
       "      <td>java, ml, ai</td>\n",
       "      <td>8.63</td>\n",
       "      <td>RohitSingh—FrontendDeveloper\\n+91-9987654321|r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>PriyaMenon MachineLearningEngineer</td>\n",
       "      <td>priya.menon@example.com</td>\n",
       "      <td>+91-9000011111</td>\n",
       "      <td>python, sql, flask, ml, ai</td>\n",
       "      <td>8.95</td>\n",
       "      <td>PriyaMenon—MachineLearningEngineer\\n+91-900001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>SUMIT CHOUDHARY</td>\n",
       "      <td>sumitxae@gmail.com</td>\n",
       "      <td>+91 6268856038</td>\n",
       "      <td>python, java, sql, ml, ai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUMIT CHOUDHARY\\nIndia — +91 6268856038 — sumi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name                      email  \\\n",
       "0                             David Kim      david_kim_91@mail.com   \n",
       "1                         Manisha Yadav  manisha_yadav_45@mail.com   \n",
       "2                           Ahmed Malik    ahmed_malik_47@mail.com   \n",
       "3                           Mia Johnson    mia_johnson_46@mail.com   \n",
       "4                           Mia Johnson    mia_johnson_49@mail.com   \n",
       "..                                  ...                        ...   \n",
       "104         Aman Verma SoftwareEngineer     aman.verma@example.com   \n",
       "105            NishthaGupta DataAnalyst  nishtha.gupta@example.com   \n",
       "106        RohitSingh FrontendDeveloper    rohit.singh@example.com   \n",
       "107  PriyaMenon MachineLearningEngineer    priya.menon@example.com   \n",
       "108                     SUMIT CHOUDHARY         sumitxae@gmail.com   \n",
       "\n",
       "                phone                      skills  cgpa  \\\n",
       "0    +91-6393136116\\n         python, sql, ml, ai   NaN   \n",
       "1    +91-9610893319\\n         python, sql, ml, ai   NaN   \n",
       "2    +91-7718575010\\n         python, sql, ml, ai   NaN   \n",
       "3    +91-8120603783\\n         python, sql, ml, ai   NaN   \n",
       "4    +91-7736163235\\n         python, sql, ml, ai   NaN   \n",
       "..                ...                         ...   ...   \n",
       "104    +91-9876543210    python, java, sql, flask  6.50   \n",
       "105    +91-9123456789      python, sql, excel, ai  7.42   \n",
       "106    +91-9987654321                java, ml, ai  8.63   \n",
       "107    +91-9000011111  python, sql, flask, ml, ai  8.95   \n",
       "108   +91 6268856038    python, java, sql, ml, ai   NaN   \n",
       "\n",
       "                                                  text  \n",
       "0    NAME: David Kim 91\\nEmail: david_kim_91@mail.c...  \n",
       "1    NAME: Manisha Yadav 45\\nEmail: manisha_yadav_4...  \n",
       "2    NAME: Ahmed Malik 47\\nEmail: ahmed_malik_47@ma...  \n",
       "3    NAME: Mia Johnson 46\\nEmail: mia_johnson_46@ma...  \n",
       "4    NAME: Mia Johnson 49\\nEmail: mia_johnson_49@ma...  \n",
       "..                                                 ...  \n",
       "104  Aman Verma— SoftwareEngineer\\n+91-9876543210|a...  \n",
       "105  NishthaGupta—DataAnalyst\\n+91-9123456789|nisht...  \n",
       "106  RohitSingh—FrontendDeveloper\\n+91-9987654321|r...  \n",
       "107  PriyaMenon—MachineLearningEngineer\\n+91-900001...  \n",
       "108  SUMIT CHOUDHARY\\nIndia — +91 6268856038 — sumi...  \n",
       "\n",
       "[109 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"resumes_extracted_new.csv\")\n",
    "\n",
    "# Remove filename & text columns\n",
    "df = df.drop(['filename'], axis=1)\n",
    "\n",
    "# Show final clean table\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14fa0b49-887f-4c61-9166-9a2b5028b7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean CSV saved as All_needed_entity.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"All_needed_entity.csv\", index=False)\n",
    "print(\"Clean CSV saved as All_needed_entity.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bec1bb10-e790-481f-ae9d-173d2d948dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded to S3 → ner-output/All_needed_entity_1765279355.csv\n"
     ]
    }
   ],
   "source": [
    "from upload_csv_to_s3 import upload_to_s3\n",
    "upload_to_s3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67721c64-f80d-4ab7-bfa5-817b39781480",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(f)\n\u001b[0;32m      5\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskills\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcgpa\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([name, email, phone, skills, cgpa])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Now upload to S3\u001b[39;00m\n\u001b[0;32m      9\u001b[0m upload_to_s3()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "# CSV created here\n",
    "import csv\n",
    "with open(\"All_needed_entity.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"name\", \"email\", \"phone\", \"skills\", \"cgpa\"])\n",
    "    writer.writerow([name, email, phone, skills, cgpa])\n",
    "\n",
    "# Now upload to S3\n",
    "upload_to_s3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7cf841-5420-4f15-a010-13589278b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "def upload_to_stage():\n",
    "    conn = snowflake.connector.connect(...)\n",
    "    cs = conn.cursor()\n",
    "    \n",
    "    cs.execute(\"\"\"\n",
    "        PUT file://All_needed_entity.csv @resume_stage\n",
    "        OVERWRITE = TRUE\n",
    "    \"\"\")\n",
    "    \n",
    "    cs.execute(\"\"\"\n",
    "        COPY INTO RESUME_DATA\n",
    "        FROM @resume_stage\n",
    "        FILE_FORMAT = (TYPE = CSV FIELD_OPTIONALLY_ENCLOSED_BY='\"' SKIP_HEADER=1)\n",
    "        ON_ERROR='CONTINUE'\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    cs.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7f4ccfc-fea4-44c9-aea2-46aec3ee9487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Snowflake Connection Successful!\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "try:\n",
    "    conn = snowflake.connector.connect(\n",
    "        user=\"SejalChourey\",\n",
    "        password=\"Snowflakespass123\",\n",
    "        account=\"oxeywss-jk90862\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"SALES_DB_NEW\",\n",
    "        schema=\"PUBLIC\"\n",
    "    )\n",
    "    print(\"nowflake Connection Successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection Failed:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c8a5996-ffd0-4d4d-9913-67cf5ecd0ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Database created or already exists.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Step 1: Connect WITHOUT database\n",
    "def connect_db_without_db():\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\"\n",
    "    )\n",
    "\n",
    "# Step 2: Create database IF NOT EXISTS\n",
    "def create_database():\n",
    "    db = connect_db_without_db()\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(\"CREATE DATABASE IF NOT EXISTS custom_ner_db\")  \n",
    "    db.commit()\n",
    "    db.close()\n",
    "    print(\"Database created or already exists.\")\n",
    "\n",
    "create_database()  # RUN THIS FIRST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86144e88-a017-45ae-aa26-6c19a5bd3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "def connect_db():\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",       \n",
    "        user=\"root\",            \n",
    "        password=\"\",            \n",
    "        database=\"custom_ner_db\"    \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b29084a-8b08-44c1-8fde-9792eb0a08cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Table created successfully!\n"
     ]
    }
   ],
   "source": [
    "db = connect_db()\n",
    "cursor = db.cursor()\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS resumes_info (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    name VARCHAR(255),\n",
    "    email VARCHAR(255),\n",
    "    phone VARCHAR(50),\n",
    "    skills TEXT,\n",
    "    cgpa VARCHAR(50)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "db.commit()\n",
    "print(\"Table created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16c7e213-0203-4c9a-949d-8d45a99d08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(\"\")   # NaN ko empty string me convert karega\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d991c483-db87-4048-a82c-00388e486417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.where(pd.notnull(df), None)  # NaN → None (MySQL NULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d79555d-b804-48f7-8e5e-ccfbbe6a47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ All data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(\"\")   # Step 1 - remove NaN\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO resumes_info (name, email, phone, skills, cgpa)\n",
    "VALUES (%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    values = (\n",
    "        str(row['name']),\n",
    "        str(row['email']),\n",
    "        str(row['phone']),\n",
    "        str(row['skills']),\n",
    "        str(row['cgpa'])\n",
    "    )\n",
    "    cursor.execute(insert_query, values)\n",
    "\n",
    "db.commit()\n",
    "print(\"✔ All data inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9034e86e-e9c3-4cd8-92af-08920ae25fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'email', 'phone', 'skills', 'cgpa', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "372f25ed-905a-4589-a6c9-4deaef16ddba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m         ents\u001b[38;5;241m.\u001b[39mappend((m\u001b[38;5;241m.\u001b[39mstart(), m\u001b[38;5;241m.\u001b[39mend(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPERSON\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ents\n\u001b[1;32m---> 11\u001b[0m nlp_base \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m candidates \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m N_SEED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df))  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_regex_spans(text):\n",
    "    ents = []\n",
    "    for m in re.finditer(r\"\\b[A-Z][a-z]+\\s[A-Z][a-z]+\\b\", text):  # Two words names\n",
    "        ents.append((m.start(), m.end(), \"PERSON\"))\n",
    "    for m in re.finditer(r\"\\b[A-Z][a-z]{2,}\\b\", text):  # Single word names\n",
    "        ents.append((m.start(), m.end(), \"PERSON\"))\n",
    "    return ents\n",
    "\n",
    "nlp_base = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "candidates = []\n",
    "N_SEED = min(100, len(df))  \n",
    "for i in range(N_SEED):\n",
    "    text = str(df.loc[i, \"text\"])  # Make sure \"text\" column exists!\n",
    "    ents = find_regex_spans(text)\n",
    "    doc = nlp_base(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            ents.append((ent.start_char, ent.end_char, \"PERSON\"))\n",
    "\n",
    "    unique = []\n",
    "    seen = set()\n",
    "    for s, e, l in sorted(ents, key=lambda x: (x[0], -x[1])):\n",
    "        key = (s, e, l)\n",
    "        if key not in seen:\n",
    "            unique.append((s, e, l))\n",
    "            seen.add(key)\n",
    "\n",
    "    candidates.append((text, {\"entities\": unique}))\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "Path(\"train_candidates.json\").write_text(\n",
    "    json.dumps(candidates, ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "print(\"Saved\", len(candidates), \"candidate examples to train_candidates.json\")\n",
    "print(\"✔ Open and correct offsets/labels for best results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74ccfa92-d3e6-4cf6-b5e2-78a25fd325f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_candidates \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_candidates.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread_text())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# shuffle and split (80/20)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(train_candidates)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "train_candidates = json.loads(Path(\"train_candidates.json\").read_text())\n",
    "\n",
    "# shuffle and split (80/20)\n",
    "random.shuffle(train_candidates)\n",
    "split_idx = int(0.8 * len(train_candidates))\n",
    "TRAIN_DATA = train_candidates[:split_idx]\n",
    "DEV_DATA = train_candidates[split_idx:]\n",
    "\n",
    "def filter_aligned(examples):\n",
    "    kept, skipped = [], 0\n",
    "    nlp_tmp = English()\n",
    "    for text, ann in examples:\n",
    "        try:\n",
    "            biluo = offsets_to_biluo_tags(nlp_tmp.make_doc(text), ann[\"entities\"])\n",
    "            if \"-\" in biluo:\n",
    "                skipped += 1\n",
    "            else:\n",
    "                kept.append((text, ann))\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "    return kept, skipped\n",
    "\n",
    "TRAIN_DATA, bad_train = filter_aligned(TRAIN_DATA)\n",
    "DEV_DATA, bad_dev = filter_aligned(DEV_DATA)\n",
    "print(\"Kept train:\", len(TRAIN_DATA), \"skipped:\", bad_train)\n",
    "print(\"Kept dev:\", len(DEV_DATA), \"skipped:\", bad_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6702ac5-9213-4a0a-8ad4-b4c6c57b6930",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mpipe_names:\n\u001b[0;32m      3\u001b[0m     ner \u001b[38;5;241m=\u001b[39m nlp\u001b[38;5;241m.\u001b[39madd_pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\", last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# add labels\n",
    "labels = set()\n",
    "for _, ann in TRAIN_DATA:\n",
    "    for s,e,l in ann[\"entities\"]:\n",
    "        labels.add(l)\n",
    "for label in labels:\n",
    "    ner.add_label(label)\n",
    "\n",
    "other_pipes = [p for p in nlp.pipe_names if p != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.resume_training()\n",
    "    for epoch in range(30):  \n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update([example], sgd=optimizer, drop=0.2, losses=losses)\n",
    "        print(f\"Epoch {epoch+1} Losses: {losses}\")\n",
    "\n",
    "# Save model\n",
    "nlp.to_disk(\"resume_ner_model_v1\")\n",
    "print(\"Model saved to resume_ner_model_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0da8454-2210-4a51-821a-8839dd414bf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp_trained \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume_ner_model_v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, ann \u001b[38;5;129;01min\u001b[39;00m DEV_DATA[:\u001b[38;5;241m10\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---- SAMPLE ----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "nlp_trained = spacy.load(\"resume_ner_model_v1\")\n",
    "\n",
    "for text, ann in DEV_DATA[:10]:\n",
    "    print(\"---- SAMPLE ----\")\n",
    "    print(text[:300], \"...\\n\")\n",
    "    print(\"GOLD:\", ann[\"entities\"])\n",
    "    pred = [(ent.start_char, ent.end_char, ent.label_, ent.text) for ent in nlp_trained(text).ents]\n",
    "    print(\"PRED:\", pred)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98049390-4af9-42c6-b827-6f565d52bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a87a06d-7091-4333-8c8d-aac68762e391",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skills' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 20\u001b[0m\n\u001b[0;32m     12\u001b[0m COMMON_SKILLS \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc++\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjavascript\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmachine learning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeep learning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdjango\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreact\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopencv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpower bi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunication\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleadership\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteamwork\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft excel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m ]\n\u001b[0;32m     19\u001b[0m SKILLS_RE \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([re\u001b[38;5;241m.\u001b[39mescape(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m COMMON_SKILLS]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, re\u001b[38;5;241m.\u001b[39mIGNORECASE)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skills:\n\u001b[0;32m     21\u001b[0m     skills \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m({m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m SKILLS_RE\u001b[38;5;241m.\u001b[39mfinditer(text)})\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Name regex (First + Last Name with capital letters)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skills' is not defined"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "import re\n",
    "\n",
    "# Email regex\n",
    "EMAIL_RE = re.compile(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\")\n",
    "\n",
    "# Phone regex (Indian + International format)\n",
    "PHONE_RE = re.compile(r\"\\b(?:\\+?\\d{1,3}[- ]?)?\\d{10}\\b\")\n",
    "CGPA_RE = re.compile(r\"(?:CGPA[:\\-]?\\s*|CGPA\\s*\\(\\s*|)(\\d\\.\\d{1,2})\")\n",
    "\n",
    "COMMON_SKILLS = [\n",
    "    \"python\", \"java\", \"c++\", \"html\", \"css\", \"javascript\", \"sql\", \"machine learning\",\n",
    "    \"deep learning\", \"django\", \"flask\", \"react\", \"tensorflow\", \"opencv\",\n",
    "    \"power bi\", \"pandas\", \"numpy\", \"git\", \"communication\", \"leadership\",\n",
    "    \"teamwork\", \"microsoft excel\", \"excel\", \"nlp\", \"data analysis\"\n",
    "]\n",
    "\n",
    "SKILLS_RE = re.compile(r\"\\b(\" + \"|\".join([re.escape(s) for s in COMMON_SKILLS]) + r\")\\b\", re.IGNORECASE)\n",
    "if not skills:\n",
    "    skills = list({m.group(0).strip() for m in SKILLS_RE.finditer(text)})\n",
    "# Name regex (First + Last Name with capital letters)\n",
    "NAME_RE = re.compile(r\"\\b[A-Z][a-z]+\\s[A-Z][a-z]+\\b\")\n",
    "\n",
    "# Also support UPPERCASE names\n",
    "UPPER_NAME_RE = re.compile(r\"\\b[A-Z]{2,}\\s[A-Z]{2,}\\b\")\n",
    "\n",
    "nlp_final = spacy.load(\"resume_ner_model_v1\")  \n",
    "nlp_default = spacy.load(\"en_core_web_sm\")    \n",
    "\n",
    "# reset output files\n",
    "for fn in [\"names.txt\",\"phones.txt\",\"emails.txt\",\"skills.txt\",\"cgpa.txt\"]:\n",
    "    Path(fn).write_text(\"\")\n",
    "\n",
    "def extract_name_spacy(text):\n",
    "    \"\"\"\n",
    "    First try resume_ner_model_v1 → if PERSON not found,\n",
    "    fallback to en_core_web_sm NER model\n",
    "    \"\"\"\n",
    "    doc1 = nlp_final(text)  # YOUR TRAINED MODEL\n",
    "    for ent in doc1.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return ent.text.strip()\n",
    "\n",
    "    # fallback with default spacy model\n",
    "    doc2 = nlp_default(text)\n",
    "    for ent in doc2.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return ent.text.strip()\n",
    "\n",
    "    return None  # nothing found\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row[\"text\"])\n",
    "    doc = nlp_final(text)\n",
    "\n",
    "     # NAME extraction \n",
    "    name = extract_name_spacy(text)\n",
    "    names = [name] if name else [] \n",
    "\n",
    "    # collect per doc\n",
    "    #names = [ent.text.strip() for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    emails = [ent.text.strip() for ent in doc.ents if ent.label_ == \"EMAIL\"]\n",
    "    phones = [ent.text.strip() for ent in doc.ents if ent.label_ == \"PHONE\"]\n",
    "    skills = [ent.text.strip() for ent in doc.ents if ent.label_ == \"SKILL\"]\n",
    "    cgpas = [ent.text.strip() for ent in doc.ents if ent.label_ == \"CGPA\"]\n",
    "\n",
    "    # fallbacks by regex if model missed\n",
    "    if not emails:\n",
    "        emails = [m.group(0) for m in EMAIL_RE.finditer(text)]\n",
    "    if not phones:\n",
    "        phones = [m.group(0) for m in PHONE_RE.finditer(text)]\n",
    "    if not cgpas:\n",
    "        cgpas = [m.group(1) for m in CGPA_RE.finditer(text)] \n",
    "    if not skills:\n",
    "        skills = list({m.group(0) for m in SKILLS_RE.finditer(text)})\n",
    "\n",
    "    # fallback\n",
    "    if not names:\n",
    "        name_match = re.search(NAME_RE, text)\n",
    "        if name_match:\n",
    "            names = [name_match.group()]\n",
    "\n",
    "    # normalize and dedupe\n",
    "    def clean_list(lst):\n",
    "        return [s for s in dict.fromkeys([x.strip() for x in lst if x and x.strip()])]\n",
    "\n",
    "    names = clean_list(names) or [\"No Name Found\"]\n",
    "    emails = clean_list(emails) or [\"No Email\"]\n",
    "    phones = clean_list(phones) or [\"No Phone\"]\n",
    "    skills = clean_list(skills) or [\"No Skills Found\"]\n",
    "    cgpas = clean_list(cgpas) or [\"No CGPA Found\"]\n",
    "\n",
    "    # write per file lines with filename tag\n",
    "    with open(\"names.txt\",\"a\",encoding=\"utf-8\") as f:\n",
    "        for v in names:\n",
    "            f.write(f\"{v}\\n\")\n",
    "\n",
    "    with open(\"emails.txt\",\"a\",encoding=\"utf-8\") as f:\n",
    "        for v in emails:\n",
    "            f.write(f\"{v}\\n\")\n",
    "\n",
    "    with open(\"phones.txt\",\"a\",encoding=\"utf-8\") as f:\n",
    "        for v in phones:\n",
    "            f.write(f\"{v}\\n\")\n",
    "\n",
    "    with open(\"skills.txt\",\"a\",encoding=\"utf-8\") as f:\n",
    "        for v in skills:\n",
    "            f.write(f\"{v}\\n\")\n",
    "\n",
    "    with open(\"cgpa.txt\",\"a\",encoding=\"utf-8\") as f:\n",
    "        for v in cgpas:\n",
    "            f.write(f\"{v}\\n\")\n",
    "\n",
    "print(\"Done — check names.txt, phones.txt, emails.txt, skills.txt, cgpa.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e78162-c457-46b7-bbe0-17e4218340fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "def connect_db():\n",
    "    return mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"\",\n",
    "        database=\"Custom_NER_db\"   # Create if not exists in next step\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531985db-5dc6-4685-945c-e79a26ed1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\"\n",
    ")\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS Custom_NER_db\")\n",
    "cursor.execute(\"USE Custom_NER_db\")\n",
    "\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS names_tbl (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    name VARCHAR(255)\n",
    ")\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS phones_tbl (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    phone VARCHAR(50)\n",
    ")\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS emails_tbl (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    email VARCHAR(255)\n",
    ")\"\"\")\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS skills_tbl\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE skills_tbl (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    skills TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS cgpa_tbl (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    cgpa FLOAT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "db.commit()\n",
    "print(\"Database and tables created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "43120e8e-4fd3-47bc-a888-cc94d9c839f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "db = connect_db()\n",
    "cursor = db.cursor()\n",
    "\n",
    "with open(\"names.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        name = line.strip()\n",
    "        cursor.execute(\"INSERT INTO names_tbl (name) VALUES (%s)\", (name,))\n",
    "\n",
    "db.commit()\n",
    "print(\"Names inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "dd0043b8-a078-44f8-9b3e-4e4345ca6ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phones inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(\"phones.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        phone = line.strip()\n",
    "        cursor.execute(\"INSERT INTO phones_tbl (phone) VALUES (%s)\", (phone,))\n",
    "db.commit()\n",
    "print(\"Phones inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ec222b3b-52ac-43bd-b4da-0c360ea32f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emails inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(\"emails.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        email = line.strip()\n",
    "        cursor.execute(\"INSERT INTO emails_tbl (email) VALUES (%s)\", (email,))\n",
    "db.commit()\n",
    "print(\"Emails inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "691f3dde-85cb-4693-9ad6-ee6737d08945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(\"skills.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        skills = line.strip()\n",
    "        cursor.execute(\"INSERT INTO skills_tbl (skills) VALUES (%s)\", (skills,))\n",
    "db.commit()\n",
    "print(\"Skills inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4a882637-bb34-4ff6-94e1-092aa6cac6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGPA inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(\"cgpa.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        cgpa = line.strip()\n",
    "        cursor.execute(\"INSERT INTO cgpa_tbl (cgpa) VALUES (%s)\", (cgpa,))\n",
    "\n",
    "db.commit()\n",
    "print(\"CGPA inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "c721971c-2e65-450c-bb5f-487a9e112691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(value):\n",
    "    if not value or str(value).strip() == \"\" or str(value).lower() == \"none\":\n",
    "        return \"NAN\"\n",
    "    return value\n",
    "\n",
    "def insert_data(name, email, phone, skills, cgpa, address):\n",
    "    db = connect_db()\n",
    "    cursor = db.cursor()\n",
    "\n",
    "    name = sanitize(name)\n",
    "    email = sanitize(email)\n",
    "    phone = sanitize(phone)\n",
    "    skills = sanitize(skills)\n",
    "    cgpa = sanitize(cgpa)\n",
    "    address = sanitize(address)\n",
    "\n",
    "    query = \"\"\"\n",
    "    INSERT INTO resumes_info (name, email, phone, skills, cgpa, address)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    values = (name, email, phone, skills, cgpa, address)\n",
    "    \n",
    "    cursor.execute(query, values)\n",
    "    db.commit()\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    print(\"✔ Record inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "5f28234e-2238-4ef5-ada2-0d371ea9b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\hp\\anaconda3\\lib\\site-packages (9.5.0)\n",
      "Requirement already satisfied: snowflake-connector-python in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Collecting cryptography>=44.0.1 (from snowflake-connector-python)\n",
      "  Using cached cryptography-46.0.3-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pyOpenSSL<26.0.0,>=24.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (25.3.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2024.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.32.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (23.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=3.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.7)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (4.15.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.13.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.10.0)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (0.11.1)\n",
      "Requirement already satisfied: boto3>=1.24 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (1.37.4)\n",
      "Requirement already satisfied: botocore>=1.24 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (1.37.4)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3>=1.24->snowflake-connector-python) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from boto3>=1.24->snowflake-connector-python) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore>=1.24->snowflake-connector-python) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from botocore>=1.24->snowflake-connector-python) (2.2.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cryptography>=44.0.1->snowflake-connector-python) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=2.0.0->cryptography>=44.0.1->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.16.0)\n",
      "Using cached cryptography-46.0.3-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "Installing collected packages: cryptography\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 42.0.5\n",
      "    Uninstalling cryptography-42.0.5:\n",
      "      Successfully uninstalled cryptography-42.0.5\n",
      "Successfully installed cryptography-46.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python\n",
    "!pip install snowflake-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "5bd00617-d49b-43b0-a9da-36ffad1111f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: cryptography 46.0.3\n",
      "Uninstalling cryptography-46.0.3:\n",
      "  Successfully uninstalled cryptography-46.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall cryptography -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "02f90d39-81f6-4ba2-9268-3c02905c5a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cryptography==42.0.5\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cryptography==42.0.5) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography==42.0.5) (2.21)\n",
      "Using cached cryptography-42.0.5-cp39-abi3-win_amd64.whl (2.9 MB)\n",
      "Installing collected packages: cryptography\n",
      "Successfully installed cryptography-42.0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyopenssl 25.3.0 requires cryptography<47,>=45.0.7, but you have cryptography 42.0.5 which is incompatible.\n",
      "snowflake-connector-python 4.1.0 requires cryptography>=44.0.1, but you have cryptography 42.0.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install cryptography==42.0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "ccbb316a-30d1-481c-8975-19b803b844c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import snowflake.connector\n",
    "\n",
    "# MySQL Connect\n",
    "mysql_conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"\",\n",
    "    database=\"Custom_NER_db\"\n",
    ")\n",
    "\n",
    "mysql_cursor = mysql_conn.cursor(dictionary=True)\n",
    "mysql_cursor.execute(\"SELECT * FROM resumes_info\")\n",
    "data = mysql_cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "a6365fd0-97ac-4278-9413-3baa20b23aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "sf_conn = snowflake.connector.connect(\n",
    "    user='SejalChourey',3\n",
    "    password='Snowflakespass123',\n",
    "    account='oxeywss-jk90862',  \n",
    "    warehouse='COMPUTE_WH',\n",
    "    database='SALES_DB_NEW',\n",
    "    schema='RAW'\n",
    ")\n",
    "\n",
    "sf_cursor = sf_conn.cursor()\n",
    "print(\"Connected!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "ed75d6cf-0c5a-45df-bbcb-fd44f23a5fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'name': 'David Kim', 'email': 'david_kim_91@mail.com', 'phone': '+91-6393136116\\n', 'skills': 'python, sql, ml, ai', 'cgpa': ''}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "5796fa64-0626-40e9-82b9-a2c99db77a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x2b1a457f1a0>"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_cursor.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE snowflake_table (\n",
    "        id INT,\n",
    "        name STRING,\n",
    "        email STRING,\n",
    "        phone STRING,\n",
    "        skills STRING,\n",
    "        cgpa STRING\n",
    "    )\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "7ffcdc90-22da-4dea-9d90-3c66f438ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    sf_cursor.execute(\"\"\"\n",
    "        INSERT INTO snowflake_table(id, name, email, phone, skills, cgpa)\n",
    "        VALUES(%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        row['id'],\n",
    "        row['name'],\n",
    "        row['email'],\n",
    "        row['phone'].strip(), \n",
    "        row['skills'],\n",
    "        row['cgpa'] if row['cgpa'] else None  \n",
    "    ))\n",
    "\n",
    "sf_conn.commit()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab01da1-4de5-4272-8684-d358b77eb8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cdd357-ebb1-4bbc-adb3-953022b07022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e2705-ae40-4c1f-8496-9ce24a9d8bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518fb92c-fe26-48ff-927f-154db814f299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f58b9-a597-4ae1-8837-413957fec877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ac283-8cc8-4755-b175-5b8d2db5dffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
